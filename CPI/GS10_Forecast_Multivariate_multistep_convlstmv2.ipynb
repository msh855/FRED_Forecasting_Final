{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate multi-step lstm\n",
    "# %pip install chart_studio --user\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import ZeroPadding1D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D, Reshape\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio\n",
    "\n",
    "# for changing the plot size in the Jupyter Notebook output\n",
    "%matplotlib inline\n",
    "# sets the plot size to 12x8\n",
    "mpl.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>IPDCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>DARfor_Step1</th>\n",
       "      <th>DARfor_Step2</th>\n",
       "      <th>DARfor_Step3</th>\n",
       "      <th>DARfor_Step4</th>\n",
       "      <th>DARfor_Step5</th>\n",
       "      <th>DARMfor_Step1</th>\n",
       "      <th>DARMfor_Step2</th>\n",
       "      <th>DARMfor_Step3</th>\n",
       "      <th>DARMfor_Step4</th>\n",
       "      <th>DARMfor_Step5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sasdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-03-01</th>\n",
       "      <td>2462.689</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>17.647</td>\n",
       "      <td>2.934254e+05</td>\n",
       "      <td>18523.05762</td>\n",
       "      <td>23.4004</td>\n",
       "      <td>23.9186</td>\n",
       "      <td>22.4925</td>\n",
       "      <td>32.6455</td>\n",
       "      <td>22.5365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-04-01</th>\n",
       "      <td>2478.744</td>\n",
       "      <td>2330.3</td>\n",
       "      <td>17.584</td>\n",
       "      <td>2.993317e+05</td>\n",
       "      <td>18534.46600</td>\n",
       "      <td>23.8989</td>\n",
       "      <td>24.2641</td>\n",
       "      <td>22.8221</td>\n",
       "      <td>33.1606</td>\n",
       "      <td>22.6807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-05-01</th>\n",
       "      <td>2493.228</td>\n",
       "      <td>2345.8</td>\n",
       "      <td>17.796</td>\n",
       "      <td>3.013730e+05</td>\n",
       "      <td>18679.66354</td>\n",
       "      <td>24.2589</td>\n",
       "      <td>24.4655</td>\n",
       "      <td>23.0418</td>\n",
       "      <td>33.3190</td>\n",
       "      <td>23.1424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-06-01</th>\n",
       "      <td>2500.989</td>\n",
       "      <td>2352.9</td>\n",
       "      <td>17.861</td>\n",
       "      <td>3.013648e+05</td>\n",
       "      <td>18849.75209</td>\n",
       "      <td>24.2866</td>\n",
       "      <td>24.6382</td>\n",
       "      <td>23.2066</td>\n",
       "      <td>33.1606</td>\n",
       "      <td>23.3156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-07-01</th>\n",
       "      <td>2499.525</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>17.801</td>\n",
       "      <td>3.050348e+05</td>\n",
       "      <td>18843.52934</td>\n",
       "      <td>23.7050</td>\n",
       "      <td>24.6670</td>\n",
       "      <td>23.3988</td>\n",
       "      <td>33.5964</td>\n",
       "      <td>23.7773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>16979.701</td>\n",
       "      <td>14096.2</td>\n",
       "      <td>120.433</td>\n",
       "      <td>1.503347e+06</td>\n",
       "      <td>518131.00000</td>\n",
       "      <td>109.2508</td>\n",
       "      <td>104.3141</td>\n",
       "      <td>103.0011</td>\n",
       "      <td>105.0774</td>\n",
       "      <td>120.4686</td>\n",
       "      <td>...</td>\n",
       "      <td>3.036702</td>\n",
       "      <td>2.923689</td>\n",
       "      <td>2.905251</td>\n",
       "      <td>2.738333</td>\n",
       "      <td>2.423327</td>\n",
       "      <td>2.680101</td>\n",
       "      <td>3.069954</td>\n",
       "      <td>2.978124</td>\n",
       "      <td>2.969964</td>\n",
       "      <td>2.659986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>17032.129</td>\n",
       "      <td>14138.7</td>\n",
       "      <td>120.683</td>\n",
       "      <td>1.515264e+06</td>\n",
       "      <td>520055.00000</td>\n",
       "      <td>109.3078</td>\n",
       "      <td>104.6945</td>\n",
       "      <td>103.5907</td>\n",
       "      <td>105.6160</td>\n",
       "      <td>122.1042</td>\n",
       "      <td>...</td>\n",
       "      <td>2.551368</td>\n",
       "      <td>3.007423</td>\n",
       "      <td>2.915597</td>\n",
       "      <td>2.886860</td>\n",
       "      <td>2.733533</td>\n",
       "      <td>2.641499</td>\n",
       "      <td>2.775589</td>\n",
       "      <td>3.007836</td>\n",
       "      <td>2.962984</td>\n",
       "      <td>3.038477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>17009.545</td>\n",
       "      <td>14113.3</td>\n",
       "      <td>121.004</td>\n",
       "      <td>1.514859e+06</td>\n",
       "      <td>523922.00000</td>\n",
       "      <td>109.1045</td>\n",
       "      <td>104.5174</td>\n",
       "      <td>103.4120</td>\n",
       "      <td>105.6055</td>\n",
       "      <td>122.6444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.551368</td>\n",
       "      <td>3.007423</td>\n",
       "      <td>2.915597</td>\n",
       "      <td>2.886860</td>\n",
       "      <td>2.733533</td>\n",
       "      <td>2.641499</td>\n",
       "      <td>2.775589</td>\n",
       "      <td>3.007836</td>\n",
       "      <td>2.962984</td>\n",
       "      <td>3.038477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>17085.082</td>\n",
       "      <td>14179.9</td>\n",
       "      <td>121.241</td>\n",
       "      <td>1.525005e+06</td>\n",
       "      <td>526889.00000</td>\n",
       "      <td>109.9431</td>\n",
       "      <td>104.9125</td>\n",
       "      <td>103.7175</td>\n",
       "      <td>105.7062</td>\n",
       "      <td>122.3672</td>\n",
       "      <td>...</td>\n",
       "      <td>2.551368</td>\n",
       "      <td>3.007423</td>\n",
       "      <td>2.915597</td>\n",
       "      <td>2.886860</td>\n",
       "      <td>2.733533</td>\n",
       "      <td>2.641499</td>\n",
       "      <td>2.775589</td>\n",
       "      <td>3.007836</td>\n",
       "      <td>2.962984</td>\n",
       "      <td>3.038477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>17131.657</td>\n",
       "      <td>14216.5</td>\n",
       "      <td>121.448</td>\n",
       "      <td>1.525005e+06</td>\n",
       "      <td>525560.00000</td>\n",
       "      <td>109.5174</td>\n",
       "      <td>104.5979</td>\n",
       "      <td>103.3590</td>\n",
       "      <td>105.4467</td>\n",
       "      <td>119.9819</td>\n",
       "      <td>...</td>\n",
       "      <td>2.551368</td>\n",
       "      <td>3.007423</td>\n",
       "      <td>2.915597</td>\n",
       "      <td>2.886860</td>\n",
       "      <td>2.733533</td>\n",
       "      <td>2.641499</td>\n",
       "      <td>2.775589</td>\n",
       "      <td>3.007836</td>\n",
       "      <td>2.962984</td>\n",
       "      <td>3.038477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RPI  W875RX1  DPCERA3M086SBEA     CMRMTSPLx       RETAILx  \\\n",
       "sasdate                                                                       \n",
       "1959-03-01   2462.689   2314.0           17.647  2.934254e+05   18523.05762   \n",
       "1959-04-01   2478.744   2330.3           17.584  2.993317e+05   18534.46600   \n",
       "1959-05-01   2493.228   2345.8           17.796  3.013730e+05   18679.66354   \n",
       "1959-06-01   2500.989   2352.9           17.861  3.013648e+05   18849.75209   \n",
       "1959-07-01   2499.525   2351.0           17.801  3.050348e+05   18843.52934   \n",
       "...               ...      ...              ...           ...           ...   \n",
       "2019-05-01  16979.701  14096.2          120.433  1.503347e+06  518131.00000   \n",
       "2019-06-01  17032.129  14138.7          120.683  1.515264e+06  520055.00000   \n",
       "2019-07-01  17009.545  14113.3          121.004  1.514859e+06  523922.00000   \n",
       "2019-08-01  17085.082  14179.9          121.241  1.525005e+06  526889.00000   \n",
       "2019-09-01  17131.657  14216.5          121.448  1.525005e+06  525560.00000   \n",
       "\n",
       "              INDPRO   IPFPNSS   IPFINAL   IPCONGD  IPDCONGD  ...  \\\n",
       "sasdate                                                       ...   \n",
       "1959-03-01   23.4004   23.9186   22.4925   32.6455   22.5365  ...   \n",
       "1959-04-01   23.8989   24.2641   22.8221   33.1606   22.6807  ...   \n",
       "1959-05-01   24.2589   24.4655   23.0418   33.3190   23.1424  ...   \n",
       "1959-06-01   24.2866   24.6382   23.2066   33.1606   23.3156  ...   \n",
       "1959-07-01   23.7050   24.6670   23.3988   33.5964   23.7773  ...   \n",
       "...              ...       ...       ...       ...       ...  ...   \n",
       "2019-05-01  109.2508  104.3141  103.0011  105.0774  120.4686  ...   \n",
       "2019-06-01  109.3078  104.6945  103.5907  105.6160  122.1042  ...   \n",
       "2019-07-01  109.1045  104.5174  103.4120  105.6055  122.6444  ...   \n",
       "2019-08-01  109.9431  104.9125  103.7175  105.7062  122.3672  ...   \n",
       "2019-09-01  109.5174  104.5979  103.3590  105.4467  119.9819  ...   \n",
       "\n",
       "            DARfor_Step1  DARfor_Step2  DARfor_Step3  DARfor_Step4  \\\n",
       "sasdate                                                              \n",
       "1959-03-01      0.000000      0.000000      0.000000      0.000000   \n",
       "1959-04-01      0.000000      0.000000      0.000000      0.000000   \n",
       "1959-05-01      0.000000      0.000000      0.000000      0.000000   \n",
       "1959-06-01      0.000000      0.000000      0.000000      0.000000   \n",
       "1959-07-01      0.000000      0.000000      0.000000      0.000000   \n",
       "...                  ...           ...           ...           ...   \n",
       "2019-05-01      3.036702      2.923689      2.905251      2.738333   \n",
       "2019-06-01      2.551368      3.007423      2.915597      2.886860   \n",
       "2019-07-01      2.551368      3.007423      2.915597      2.886860   \n",
       "2019-08-01      2.551368      3.007423      2.915597      2.886860   \n",
       "2019-09-01      2.551368      3.007423      2.915597      2.886860   \n",
       "\n",
       "            DARfor_Step5  DARMfor_Step1  DARMfor_Step2  DARMfor_Step3  \\\n",
       "sasdate                                                                 \n",
       "1959-03-01      0.000000       0.000000       0.000000       0.000000   \n",
       "1959-04-01      0.000000       0.000000       0.000000       0.000000   \n",
       "1959-05-01      0.000000       0.000000       0.000000       0.000000   \n",
       "1959-06-01      0.000000       0.000000       0.000000       0.000000   \n",
       "1959-07-01      0.000000       0.000000       0.000000       0.000000   \n",
       "...                  ...            ...            ...            ...   \n",
       "2019-05-01      2.423327       2.680101       3.069954       2.978124   \n",
       "2019-06-01      2.733533       2.641499       2.775589       3.007836   \n",
       "2019-07-01      2.733533       2.641499       2.775589       3.007836   \n",
       "2019-08-01      2.733533       2.641499       2.775589       3.007836   \n",
       "2019-09-01      2.733533       2.641499       2.775589       3.007836   \n",
       "\n",
       "            DARMfor_Step4  DARMfor_Step5  \n",
       "sasdate                                   \n",
       "1959-03-01       0.000000       0.000000  \n",
       "1959-04-01       0.000000       0.000000  \n",
       "1959-05-01       0.000000       0.000000  \n",
       "1959-06-01       0.000000       0.000000  \n",
       "1959-07-01       0.000000       0.000000  \n",
       "...                   ...            ...  \n",
       "2019-05-01       2.969964       2.659986  \n",
       "2019-06-01       2.962984       3.038477  \n",
       "2019-07-01       2.962984       3.038477  \n",
       "2019-08-01       2.962984       3.038477  \n",
       "2019-09-01       2.962984       3.038477  \n",
       "\n",
       "[727 rows x 153 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qd = pd.read_csv(r'FRED_QD_20191113.csv', header=0, skiprows=[1,2])\n",
    "md = pd.read_csv(r'FRED_MD_20191113.csv', header=0, skiprows=[1,2])\n",
    "data = md\n",
    "# data['CPI'] = ((data['CPIAUCSL'].shift(-12) / data['CPIAUCSL']) - 1)*100\n",
    "# data = md.merge(qd, how='left', on='sasdate')\n",
    "# data['GDP_pad'] = data.GDPC1.fillna(method='pad')\n",
    "# data['GDP_pad_shift'] = data['GDP_pad'].shift(-3)\n",
    "# data['GDP_change'] = (data['GDP_pad_shift'] - data['GDP_pad'])/3\n",
    "# data['GDP'] = data['GDP_change'].cumsum() + data['GDPC1'][1]\n",
    "data['sasdate'] = pd.to_datetime(data['sasdate'], format=\"%m/%d/%Y\")\n",
    "data.set_index('sasdate', inplace=True)\n",
    "# data = data.loc[:, ~data.columns.str.contains('_y')]\n",
    "# data = data.drop(['GDP_pad', 'GDP_pad_shift', 'GDP_change'], axis=1)\n",
    "data = data.fillna(method='pad').fillna(0).iloc[1:,:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_1(data, train_share, idx=None):\n",
    "    '''split a univariate dataset into train/test sets'''\n",
    "    if idx is not None:\n",
    "        index = idx\n",
    "    else: \n",
    "        index = round(len(data)*train_share)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "    train, test = data[:index], data[index:]\n",
    "    return train, test\n",
    "    # restructure into windows of yearly data\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences_multi(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequences[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    " \n",
    "    \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    " \n",
    "    \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    yhat_list = []\n",
    "    j = 0\n",
    "    for y in yhat:\n",
    "        yhat_list.append(y + history[-(interval-j)])\n",
    "        j += 1\n",
    "    return yhat_list\n",
    " \n",
    "    \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    " \n",
    "    \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value, n_out):\n",
    "#     print(X)\n",
    "#     print(value)\n",
    "    new_row = [x for x in X] + [y for y in value[0]]\n",
    "#     print(new_row)\n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -n_out:]\n",
    "\n",
    "\n",
    "def moving(x, window):\n",
    "    ret = np.cumsum(x, dtype=float)\n",
    "    ret[window:] = ret[window:] - ret[:-window]\n",
    "    return ret[window - 1:] / window\n",
    "\n",
    "\n",
    "def moving_frame(x, window_list=[3]):\n",
    "    frame = pd.DataFrame()\n",
    "    for i in window_list:\n",
    "        frame['{}'.format(i)] = np.pad(moving(x, i), (i-1,0),'constant', constant_values=(0))\n",
    "    return frame.values\n",
    "        \n",
    "\n",
    "def model_branch(input_shape, filter_size, dense_neuron=100, nb_filters=10, drop=.3, batch_size=1):\n",
    "    #the input is a time series of length n and width 19\n",
    "    input_seq = Input(batch_shape=(batch_size, input_shape[1], input_shape[2]))\n",
    "    #1-D convolution and global max-pooling\n",
    "    conv = Conv1D(nb_filters, filter_size, padding=\"same\", activation=\"relu\")(input_seq)\n",
    "#     pool = GlobalMaxPooling1D()(conv)\n",
    "    #dense layer with dropout regularization\n",
    "#     flat = Flatten()(pool)\n",
    "#     compressed = Dense(dense_neuron, activation=\"relu\")(flat)\n",
    "#     compressed = Dropout(drop)(compressed)\n",
    "    model = Model(inputs=input_seq, outputs=conv)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_cnn(merged_shape, nb_filters=10, filter_size=8):\n",
    "    input_seq = Input(shape=(merged_shape))\n",
    "    conv1 = Conv1D(nb_filters, filter_size, padding=\"same\", activation=\"relu\")(input_seq)\n",
    "    pool1 = GlobalMaxPooling1D()(conv1)\n",
    "    model = Model(inputs=input_seq, outputs=pool1)\n",
    "    return model\n",
    "\n",
    "\n",
    "# fit an CONV network to training data\n",
    "def fit_convlstm(train, validate=False, batch_size=1, nb_epoch=1000, neurons=(100,100,100), filter_size=8, \n",
    "                 drop=.5, loss='mean_absolute_error', verbose=0, iteration=0, optimizer='sgd', \n",
    "                 callback=False, window=24, stepsout=12, l_rate=.0001, decay=0, patience=100, \n",
    "                 average_window=[3, 6, 12]):\n",
    "\n",
    "    if validate:\n",
    "        orig, y_train= split_sequence(train, window, stepsout)\n",
    "        moving_average = split_sequences_multi(moving_frame(train, average_window), window, stepsout)[:-1]\n",
    "        orig_val = orig[::10]\n",
    "        orig_val = orig_val.reshape(orig_val.shape[0], orig_val.shape[1], 1)\n",
    "        moving_average_val = moving_average[::10]\n",
    "        moving_average_val = moving_average_val.reshape(moving_average_val.shape[0], moving_average_val.shape[1], \n",
    "                                                        moving_average_val.shape[2])\n",
    "        orig = orig[np.mod(np.arange(orig.shape[0]),10)!=0]\n",
    "        orig = orig.reshape(orig.shape[0], orig.shape[1], 1)\n",
    "        moving_average = moving_average[np.mod(np.arange(moving_average.shape[0]),10)!=0]\n",
    "        moving_average = moving_average.reshape(moving_average.shape[0], moving_average.shape[1], \n",
    "                                                moving_average.shape[2])\n",
    "        y_val = y_train[::10]\n",
    "        n_output_val = y_val.shape[1] * y_val.shape[2]\n",
    "        y_val = y_val.reshape((y_val.shape[0], n_output_val))\n",
    "        y_train = y_train[np.mod(np.arange(y_train.shape[0]),10)!=0]\n",
    "        val = ([orig_val, moving_average_val], y_val)\n",
    "    else:\n",
    "        val=None\n",
    "        orig, y_train= split_sequence(train, window, stepsout)\n",
    "        moving_average = split_sequences_multi(moving_frame(train, average_window), window, stepsout)\n",
    "        moving_average = moving_average.reshape(moving_average.shape[0], moving_average.shape[1], \n",
    "                                                moving_average.shape[2])\n",
    "    \n",
    "    if iteration == 0:\n",
    "        keras.backend.clear_session() \n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=l_rate, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = keras.optimizers.SGD(learning_rate=l_rate, momentum=0.9, nesterov=True)\n",
    "    if callback:\n",
    "        earlystop = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)]\n",
    "    else:\n",
    "        earlystop = None\n",
    "    \n",
    "    if iteration == 0:\n",
    "        n_output = y_train.shape[1] * y_train.shape[2]\n",
    "        y_train = y_train.reshape((y_train.shape[0], n_output))\n",
    "\n",
    "        input_raw = Input(batch_shape=(batch_size, orig.shape[1],orig.shape[2]))\n",
    "        input_smooth = Input(batch_shape=(batch_size, moving_average.shape[1], moving_average.shape[2]))\n",
    "\n",
    "        raw_branch = model_branch(orig.shape, filter_size, dense_neuron=neurons[0], batch_size=batch_size)\n",
    "        smooth_branch = model_branch(moving_average.shape, filter_size, dense_neuron=neurons[0], \n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "        raw_embedding = raw_branch(input_raw)\n",
    "        smooth_embedding = smooth_branch(input_smooth)\n",
    "\n",
    "        merged = concatenate([raw_embedding, smooth_embedding])\n",
    "    #     cnn_model = model_cnn(merged.get_shape()[1])\n",
    "    #     cnn_model = TimeDistributed(cnn_model)\n",
    "    #     cnn = cnn_model(merged)\n",
    "    #     cnn = cnn_model(merged)\n",
    "    #     shp1 = Reshape((1,cnn.shape[1]))(cnn)\n",
    "        skip00 = concatenate([input_raw, input_smooth, merged])\n",
    "        skip00 = concatenate([skip00, merged])\n",
    "        dropout00 = Dropout(drop)(skip00)\n",
    "        lstm1 = LSTM(neurons[1], return_sequences=True, stateful=True)(dropout00)\n",
    "        lstm2 = LSTM(neurons[1], return_sequences=True, stateful=True)(lstm1)\n",
    "        skip0 = concatenate([lstm2, merged])\n",
    "        dropout0 = Dropout(drop)(skip0)\n",
    "        dense1 = Dense(neurons[2], activation='relu')(dropout0)\n",
    "        dense2 = Dense(neurons[2], activation='relu')(dense1)\n",
    "        dense3 = Dense(neurons[2], activation='relu')(dense2)\n",
    "        skip1 = concatenate([dense3, lstm2])\n",
    "        dropout1 = Dropout(drop)(skip1)\n",
    "        dense4 = Dense(neurons[2]*.75, activation='relu')(dropout1)\n",
    "        dense5 = Dense(neurons[2]*.75, activation='relu')(dense4)\n",
    "        dense6 = Dense(neurons[2]*.75, activation='relu')(dense5) \n",
    "        skip2 = concatenate([dense6, skip1])\n",
    "        dropout2 = Dropout(drop)(skip2)\n",
    "        dense7 = Dense(neurons[2]*.75*.75, activation='relu')(dropout2)\n",
    "        dense8 = Dense(neurons[2]*.75*.75, activation='relu')(dense7)\n",
    "        dense9 = Dense(neurons[2]*.75*.75, activation='relu')(dense8)    \n",
    "        skip3 = concatenate([dense9, skip2])\n",
    "        dropout = Dropout(drop)(skip3)\n",
    "        output = Dense(n_output)(dropout)\n",
    "        model = Model(inputs=[input_raw, input_smooth], outputs=output)\n",
    "        model.compile(loss=loss, optimizer=opt)\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "    if validate:\n",
    "        model_loss = model.fit([orig, moving_average], y_train, validation_data=val,\n",
    "                               epochs=nb_epoch, batch_size=batch_size, verbose=2, shuffle=False,\n",
    "                               callbacks=earlystop)\n",
    "        return model, model_loss.history['loss'], model_loss.history['val_loss']\n",
    "    else:\n",
    "        model_loss = model.fit([orig, moving_average], y_train, validation_data=val,\n",
    "                                epochs=nb_epoch, batch_size=batch_size, verbose=2, shuffle=False,\n",
    "                                callbacks=earlystop)\n",
    "        return model, model_loss.history['loss'], None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(1, 24, 1)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(1, 24, 3)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (1, 24, 10)          50          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (1, 24, 10)          130         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (1, 24, 20)          0           model[1][0]                      \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (1, 24, 24)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (1, 24, 44)          0           concatenate_1[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (1, 24, 44)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (1, 24, 600)         1548000     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (1, 24, 600)         2882400     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (1, 24, 620)         0           lstm_1[0][0]                     \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (1, 24, 620)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (1, 24, 600)         372600      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (1, 24, 600)         360600      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (1, 24, 600)         360600      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (1, 24, 1200)        0           dense_2[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (1, 24, 1200)        0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (1, 24, 450)         540450      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (1, 24, 450)         202950      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (1, 24, 450)         202950      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (1, 24, 1650)        0           dense_5[0][0]                    \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (1, 24, 1650)        0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (1, 24, 337)         556387      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (1, 24, 337)         113906      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (1, 24, 337)         113906      dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (1, 24, 1987)        0           dense_8[0][0]                    \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (1, 24, 1987)        0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (1, 24, 12)          23856       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,278,785\n",
      "Trainable params: 7,278,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 425 samples, validate on 48 samples\n",
      "Epoch 1/25000\n",
      "425/425 - 9s - loss: 0.1317 - val_loss: 0.1260\n",
      "Epoch 2/25000\n",
      "425/425 - 5s - loss: 0.1284 - val_loss: 0.1244\n",
      "Epoch 3/25000\n",
      "425/425 - 5s - loss: 0.1274 - val_loss: 0.1239\n",
      "Epoch 4/25000\n",
      "425/425 - 5s - loss: 0.1270 - val_loss: 0.1237\n",
      "Epoch 5/25000\n",
      "425/425 - 5s - loss: 0.1269 - val_loss: 0.1236\n",
      "Epoch 6/25000\n",
      "425/425 - 5s - loss: 0.1269 - val_loss: 0.1235\n",
      "Epoch 7/25000\n",
      "425/425 - 5s - loss: 0.1268 - val_loss: 0.1235\n",
      "Epoch 8/25000\n",
      "425/425 - 5s - loss: 0.1268 - val_loss: 0.1234\n",
      "Epoch 9/25000\n",
      "425/425 - 5s - loss: 0.1268 - val_loss: 0.1234\n",
      "Epoch 10/25000\n",
      "425/425 - 5s - loss: 0.1268 - val_loss: 0.1234\n",
      "Epoch 11/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1234\n",
      "Epoch 12/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1234\n",
      "Epoch 13/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1234\n",
      "Epoch 14/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 15/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 16/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 17/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 18/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 19/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 20/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 21/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 22/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 23/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 24/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 25/25000\n",
      "425/425 - 5s - loss: 0.1267 - val_loss: 0.1233\n",
      "Epoch 26/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 27/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 28/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 29/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 30/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 31/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 32/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 33/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 34/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 35/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1233\n",
      "Epoch 36/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 37/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 38/25000\n",
      "425/425 - 5s - loss: 0.1266 - val_loss: 0.1232\n",
      "Epoch 39/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 40/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 41/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 42/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 43/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 44/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 45/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 46/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 47/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 48/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 49/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 50/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 51/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 52/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 53/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1233\n",
      "Epoch 54/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 55/25000\n",
      "425/425 - 5s - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 56/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 57/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 58/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 59/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 60/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 61/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 62/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 63/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 64/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 65/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 66/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 67/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 68/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 69/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 70/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 71/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 72/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 73/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1233\n",
      "Epoch 74/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 75/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 76/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 77/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 78/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 79/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 80/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 81/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 82/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 83/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 84/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 85/25000\n",
      "425/425 - 5s - loss: 0.1264 - val_loss: 0.1232\n",
      "Epoch 86/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 87/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 88/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 89/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 90/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 91/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 92/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 93/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 94/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 95/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 96/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1233\n",
      "Epoch 97/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 98/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1233\n",
      "Epoch 99/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 100/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1232\n",
      "Epoch 101/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1232\n",
      "Epoch 102/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 103/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1233\n",
      "Epoch 104/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1233\n",
      "Epoch 105/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1232\n",
      "Epoch 106/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 107/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 108/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 109/25000\n",
      "425/425 - 5s - loss: 0.1263 - val_loss: 0.1233\n",
      "Epoch 110/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 111/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 112/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 113/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 114/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 115/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 116/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 117/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 118/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 119/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 120/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 121/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 122/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 123/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 124/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 125/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 126/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 127/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 128/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 129/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 130/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 131/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 132/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 133/25000\n",
      "425/425 - 5s - loss: 0.1261 - val_loss: 0.1233\n",
      "Epoch 134/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 135/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 136/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 137/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 138/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 139/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 140/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 141/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 142/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1234\n",
      "Epoch 143/25000\n",
      "425/425 - 5s - loss: 0.1261 - val_loss: 0.1233\n",
      "Epoch 144/25000\n",
      "425/425 - 5s - loss: 0.1261 - val_loss: 0.1233\n",
      "Epoch 145/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 146/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n",
      "Epoch 147/25000\n",
      "425/425 - 5s - loss: 0.1261 - val_loss: 0.1233\n",
      "Epoch 148/25000\n",
      "425/425 - 5s - loss: 0.1261 - val_loss: 0.1233\n",
      "Epoch 149/25000\n",
      "425/425 - 5s - loss: 0.1262 - val_loss: 0.1233\n"
     ]
    }
   ],
   "source": [
    "# transform data to be stationary\n",
    "raw_values = data.GS10.values\n",
    "diff_values = difference(raw_values, 1)\n",
    " \n",
    "# transform data to be supervised learning\n",
    "# supervised = timeseries_to_supervised(diff_values, 1)\n",
    "# print(supervised.shape)\n",
    "# supervised_values = supervised.values\n",
    " \n",
    "# split data into train and test-sets\n",
    "train, test = split_dataset_1(diff_values, .7)\n",
    " \n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train.values.reshape(-1, 1), test.values.reshape(-1, 1))\n",
    "\n",
    "window=24\n",
    "stepsout=12\n",
    "# fit the model\n",
    "time_start = datetime.now()\n",
    "conv_model, loss, val_loss = fit_convlstm(train_scaled, validate=True, batch_size=1, nb_epoch=25000,\n",
    "                                          neurons=(600,600,600), filter_size=4, drop=0.4, optimizer='sgd',\n",
    "                                          window=window, callback=True, stepsout=stepsout, l_rate=.0001,\n",
    "                                          patience=100)\n",
    "time_fit = datetime.now() - time_start\n",
    "\n",
    "# # forecast the entire training dataset to build up state for forecasting\n",
    "# # train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "\n",
    "# orig_test = test[:, 0].reshape(test.shape[0], 1, 1)\n",
    "# moving_average_test = moving_frame(test[:, 0], [3, 6, 12])\n",
    "# moving_average_test = moving_average_test.reshape(moving_average_test.shape[0], moving_average_test.shape[1], 1)\n",
    "# predictions = conv_model.predict([orig_test, moving_average_test], batch_size=None)\n",
    "loss += [np.nan] * (25000 - len(loss))\n",
    "val_loss += [np.nan] * (25000 - len(val_loss))\n",
    "loss_df = pd.DataFrame({'loss': loss})\n",
    "val_loss_df = pd.DataFrame({'val_loss': val_loss})\n",
    "\n",
    "start_idx = window + stepsout\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "history = train.values[:start_idx]\n",
    "for i in range(len(train[start_idx:])):\n",
    "    scaler, train_scaled, test_scaled = scale(history.reshape(-1, 1), train[i+start_idx].reshape(1,-1))\n",
    "    # make one-step forecast\n",
    "    train_stack = np.vstack((train_scaled, test_scaled))\n",
    "    split = split_sequence(train_stack, window, stepsout)\n",
    "    X = split[0][-1]\n",
    "    y = split[1][-1]\n",
    "    orig_ = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    moving_average_ = split_sequences_multi(moving_frame(train_stack, [3, 6, 12]), window, stepsout)[-1]\n",
    "    moving_average_ = moving_average_.reshape(1, moving_average_.shape[0], \n",
    "                                            moving_average_.shape[1])\n",
    "    yhat = conv_model.predict([orig_, moving_average_], batch_size=1)\n",
    "    yhat = yhat[-1]\n",
    "#     print(yhat.shape)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat, stepsout)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, interval=len(train[start_idx:])+len(test)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    history = np.append(history, train[i+start_idx])\n",
    "    \n",
    "history = train.values\n",
    "iteration = 0\n",
    "for i in range(len(test)):\n",
    "    scaler, train_scaled, test_scaled = scale(history.reshape(-1, 1), test.values[i].reshape(1, -1))\n",
    "    # make one-step forecast\n",
    "    train_stack = np.vstack((train_scaled, test_scaled))\n",
    "    split = split_sequence(train_stack, window, stepsout)\n",
    "    X = split[0][-1]\n",
    "    y = split[1][-1]\n",
    "    orig_ = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    moving_average_ = split_sequences_multi(moving_frame(train_stack, [3, 6, 12]), window, stepsout)[-1]\n",
    "    moving_average_ = moving_average_.reshape(1, moving_average_.shape[0], \n",
    "                                            moving_average_.shape[1])\n",
    "    yhat = conv_model.predict([orig_, moving_average_], batch_size=1)\n",
    "    yhat = yhat[-1]\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat, stepsout)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, interval=len(test)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    history = np.append(history, test.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 0:12:01.045794\n",
      "https://plot.ly/~acertainKnight/31/\n",
      "   Overall MAE  Overall MSE Period  Test MAE  Test MSE\n",
      "0     0.019951     0.002875    T+1  0.006647  0.000058\n",
      "0     0.023344     0.003715   T+10  0.005885  0.000044\n",
      "0     0.019692     0.002862   T+11  0.005528  0.000042\n",
      "0     0.022058     0.002880   T+12  0.007534  0.000079\n",
      "0     0.020805     0.002700    T+2  0.006363  0.000066\n",
      "0     0.020531     0.002603    T+3  0.005390  0.000051\n",
      "0     0.018355     0.002831    T+4  0.002452  0.000011\n",
      "0     0.021670     0.003366    T+5  0.006591  0.000051\n",
      "0     0.020945     0.002988    T+6  0.005556  0.000059\n",
      "0     0.020465     0.003142    T+7  0.006037  0.000048\n",
      "0     0.019331     0.003199    T+8  0.003601  0.000019\n",
      "0     0.019634     0.002734    T+9  0.005582  0.000042\n",
      "Overall MAE    0.020565\n",
      "Overall MSE    0.002991\n",
      "Test MAE       0.005597\n",
      "Test MSE       0.000047\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_46.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Time to train:', time_fit)\n",
    "predictions_array = np.array(predictions)\n",
    "# data_plt = pd.DataFrame(data.CPIAUCSL['2001-08-01':])\n",
    "pred_df = pd.DataFrame({'T+1': predictions_array[:, 0], 'T+2': predictions_array[:, 1],\n",
    "                         'T+3': predictions_array[:, 2], 'T+4': predictions_array[:, 3],\n",
    "                         'T+5': predictions_array[:, 4], 'T+6': predictions_array[:, 5],\n",
    "                         'T+7': predictions_array[:, 6], 'T+8': predictions_array[:, 7],\n",
    "                         'T+9': predictions_array[:, 8], 'T+10': predictions_array[:, 9],\n",
    "                         'T+11': predictions_array[:, 10], 'T+12': predictions_array[:, 11]})\n",
    "\n",
    "pred_plt = pd.DataFrame({'T+1' : pred_df['T+1'], 'T+2' : pred_df['T+2'].shift(1),\n",
    "                         'T+3' : pred_df['T+3'].shift(2), 'T+4' : pred_df['T+4'].shift(3),\n",
    "                         'T+5' : pred_df['T+5'].shift(4), 'T+6' : pred_df['T+6'].shift(5),\n",
    "                         'T+7' : pred_df['T+7'].shift(6), 'T+8' : pred_df['T+8'].shift(7),\n",
    "                         'T+9' : pred_df['T+9'].shift(8), 'T+10' : pred_df['T+10'].shift(9),\n",
    "                         'T+11': pred_df['T+11'].shift(10), 'T+12' : pred_df['T+12'].shift(11)})\n",
    "# for col in list(pred_plt):\n",
    "#     pred_plt['{}_cpi'.format(col)] = ((pred_plt[col].shift(-12) / pred_plt[col]) - 1)*100\n",
    "# for col in list(pred_plt)[:-12]:\n",
    "#     pred_plt['{}_cpi_diff'.format(col)] = pred_plt[col].shift(-1) - pred_plt[col]\n",
    "\n",
    "pred_plt['raw_values'] = raw_values[start_idx:-1]\n",
    "pred_plt['raw_'] = data.GS10.values[start_idx:-1]\n",
    "pred_plt['SPF T+1'] = data.SPFfor_Step1.values[start_idx:-1]\n",
    "pred_plt['SPF T+3'] = data.SPFfor_Step2.values[start_idx:-1]\n",
    "pred_plt['SPF T+6'] = data.SPFfor_Step3.values[start_idx:-1]\n",
    "pred_plt['SPF T+9'] = data.SPFfor_Step4.values[start_idx:-1]\n",
    "pred_plt['SPF T+12'] = data.SPFfor_Step5.values[start_idx:-1]\n",
    "\n",
    "pred_plt['DARM T+1'] = data.DARMfor_Step1.values[start_idx:-1]\n",
    "pred_plt['DARM T+3'] = data.DARMfor_Step2.values[start_idx:-1]\n",
    "pred_plt['DARM T+6'] = data.DARMfor_Step3.values[start_idx:-1]\n",
    "pred_plt['DARM T+9'] = data.DARMfor_Step4.values[start_idx:-1]\n",
    "pred_plt['DARM T+12'] = data.DARMfor_Step5.values[start_idx:-1]\n",
    "\n",
    "cols = ['SPF T+1','SPF T+3','SPF T+6','SPF T+9','SPF T+12', \n",
    "        'DARM T+1','DARM T+3','DARM T+6','DARM T+9','DARM T+12']\n",
    "pred_plt[cols] = pred_plt[cols].replace({0:np.nan})\n",
    "\n",
    "# pred_plt['raw_cpi_diff'] = pred_plt['raw_values'].shift(-1) - pred_plt['raw_values']\n",
    "pred_plt['date'] = data.index[start_idx:-1]\n",
    "pred_plt.set_index('date', inplace=True)\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (24,16)\n",
    "\n",
    "results = pd.DataFrame({'Period':[], 'Overall MSE':[], 'Overall MAE':[], 'Test MSE':[], 'Test MAE':[]})\n",
    "\n",
    "for col in list(pred_plt)[:-12]:\n",
    "    ovr_mse = mean_squared_error(pred_plt['raw_'].values[11:-23], pred_plt[col].values[11:-23])\n",
    "    ovr_mae = mean_absolute_error(pred_plt['raw_'].values[11:-23], pred_plt[col].values[11:-23])\n",
    "    test_mse = mean_squared_error(pred_plt['raw_'].iloc[round((len(pred_plt)-20)*.7):-23], \n",
    "                                  pred_plt[col].iloc[round((len(pred_plt)-20)*.7):-23])\n",
    "    test_mae = mean_absolute_error(pred_plt['raw_'].iloc[round((len(pred_plt)-20)*.7):-23], \n",
    "                                   pred_plt[col].iloc[round((len(pred_plt)-20)*.7):-23])\n",
    "#     print(col,': Overall RMSE: %.3f' % sqrt(ovr_mse), 'Test RMSE: %.3f' % sqrt(test_mse))\n",
    "#     print(col,': Overall MAE: %.3f' % ovr_mae, 'Test MAE: %.3f' % test_mae)\n",
    "    row = pd.DataFrame({'Period':[col], 'Overall MSE':[ovr_mse], 'Overall MAE':[ovr_mae], 'Test MSE':[test_mse], 'Test MAE':[test_mae]})\n",
    "    results = results.append(row)\n",
    "    \n",
    "# for col in list(pred_plt)[:-2]:\n",
    "#     plt.plot(pred_plt[col][:-23], label=col)\n",
    "# # line plot of observed vs predicted\n",
    "# # plt.plot(raw_values[20:], color='blue')\n",
    "# plt.plot(pred_plt['raw_'][:-23], color='green', label='RAW')\n",
    "# # plt.plot(test[:,0], color='green')\n",
    "# plt.legend(prop={'size': 20})\n",
    "# plt.show()\n",
    "\n",
    "# for col in list(pred_plt)[:-2]:\n",
    "#     plt.plot(pred_plt[col].iloc[round((len(pred_plt)-20)*.7):-23], label=col)\n",
    "# plt.plot(pred_plt['raw_'].iloc[round((len(pred_plt)-20)*.7):-23], color='green', label='RAW')\n",
    "# # plt.plot(test[:,0], color='green')\n",
    "# plt.legend(prop={'size': 20})\n",
    "# plt.show()\n",
    "\n",
    "# i = 0\n",
    "# for col in list(pred_plt)[:-2]:\n",
    "#     plt.plot(pred_plt[col].iloc[round((len(pred_plt)-20)*.7):-23], label=col)\n",
    "#     plt.plot(pred_plt['raw_'].iloc[round((len(pred_plt)-20)*.7):-23], color='green', label='RAW')\n",
    "#     plt.title(col)\n",
    "#     plt.show()\n",
    "\n",
    "colorlist = ['#27ACAA', '#A4E9B9', '#228941', \n",
    "             '#9EE9E8', '#1D817F', '#A97FF0',\n",
    "             '#2E0C68', '#FFB3AF', '#9B0800',\n",
    "             '#FF6D00', '#BF5200', '#0C4672',\n",
    "             '#057ED8']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.update_layout(\n",
    "    paper_bgcolor='#FFFFFF',\n",
    "    plot_bgcolor='#FFFFFF'\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(x=list(pred_plt.index),\n",
    "                   y=list(pred_plt['raw_']),\n",
    "                   name='10-year rate',\n",
    "                   line=dict(color=colorlist[0])),)\n",
    "\n",
    "# Add Traces\n",
    "i = 0\n",
    "for col in ['T+1','T+2','T+3','T+4','T+5','T+6','T+7','T+8','T+9','T+10','T+11','T+12']:\n",
    "    i+=1\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=list(pred_plt.index),\n",
    "                   y=list(pred_plt[col]),\n",
    "                   name='Model '+col,\n",
    "                   line=dict(color=colorlist[i], dash='dash')))\n",
    "    \n",
    "for col in cols:\n",
    "    i+=1\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=list(pred_plt.index),\n",
    "                   y=list(pred_plt[col]),\n",
    "                   name=col,\n",
    "                   line=dict(dash='dot')))\n",
    "    \n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=go.layout.XAxis(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=218,\n",
    "                     label=\"Test period\",\n",
    "                     step=\"month\",\n",
    "                     stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        go.layout.Updatemenu(\n",
    "            active=0,\n",
    "            buttons=list([\n",
    "                dict(label=\"T+1\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, True, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, True, False, False,\n",
    "                                       False, False, True, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - One month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+2\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, True, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Two month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+3\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, True,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, True, False,\n",
    "                                       False, False, False, True, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Three month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+4\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Four month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+5\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, True, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Five month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+6\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, True, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, True,\n",
    "                                       False, False, False, False, True,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Six month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+7\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, True,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Seven month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+8\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Eight month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+9\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, True, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       True, False, False, False, False,\n",
    "                                       True, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Nine month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+10\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, True, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Ten month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+11\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, True,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate - Eleven month\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"T+12\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       True, False, False, False,\n",
    "                                       False, True, False, False, False,\n",
    "                                       False, True]},\n",
    "                           {\"title\": \"10-year Bond Rate - One year\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"All Forecasts\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, True, True, True,\n",
    "                                       True, True, True, True,\n",
    "                                       True, True, True, True,\n",
    "                                       True, False, False, False,\n",
    "                                       False, False, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate Model Forecasts\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"All SPF\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, True, True, True,\n",
    "                                       True, True, False, False, False,\n",
    "                                       False, False]},\n",
    "                           {\"title\": \"10-year Bond Rate SPF Forecasts\",\n",
    "                            \"annotations\": []}]),\n",
    "                dict(label=\"All DARM\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\"visible\": [True, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, False, False,\n",
    "                                       False, False, True, True, True,\n",
    "                                       True, True]},\n",
    "                           {\"title\": \"10-year Bond Rate DARM Forecasts\",\n",
    "                            \"annotations\": []}])\n",
    "            ]),\n",
    "            direction=\"down\",\n",
    "            pad={\"r\": 0, \"t\": 0},\n",
    "            showactive=True,\n",
    "            x=0,\n",
    "            xanchor=\"left\",\n",
    "            y=1,\n",
    "            yanchor=\"top\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "username = 'acertainKnight' # your username \n",
    "api_key = 'NPRtVstPcJfKUz8ZzM9P' # your api key - go to profile > settings > regenerate key \n",
    "chart_studio.tools.set_credentials_file(username=username, api_key=api_key)\n",
    "\n",
    "# first_plot_url = py.plot(fig, filename='10-year Bond Rate', auto_open=False,)\n",
    "print(first_plot_url)\n",
    "print(results)\n",
    "print(results.mean())\n",
    "fig.show(renderer='iframe')\n",
    "import plotly.io as pio\n",
    "pio.write_html(fig, file='index.html', auto_open=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_df['loss'], color='red', label='loss')\n",
    "plt.plot(val_loss_df['val_loss'], color='green', label='val_loss')\n",
    "plt.legend(prop={'size': 20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
